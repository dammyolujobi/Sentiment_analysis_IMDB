{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'clf__C': 1, 'features__tfidf__min_df': 5, 'features__tfidf__ngram_range': (1, 2)}\n",
      "Accuracy: 0.9003\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "ROC-AUC:\n",
      " 0.9643635199999999\n",
      "Confusion Matrix:\n",
      " [[4455  545]\n",
      " [ 452 4548]]\n",
      "\n",
      "Some misclassified examples:\n",
      "\n",
      "Review: I saw this film shortly after watching Moonlight & Valentino with Elizabeth Perkins, Gwyneth Platrow, Whoopi Goldberg and Kathleen Turner. There are a lot of similarities between the two films. They b...\n",
      "True: negative, Pred: positive\n",
      "\n",
      "Review: \"Alexander Nevsky\" marked director Sergei Eisenstein's return to film-making after a period of exile, and what he produced is a bald-faced propaganda film proclaiming Russia's superiority over Germany...\n",
      "True: positive, Pred: negative\n",
      "\n",
      "Review: I wasn't planning on watching wasted when I saw the MTV preview but since I had nothing better to do or watch on a Sunday night I watched it.<br /><br />Wasted was no Requiem for a Dream but it was a ...\n",
      "True: positive, Pred: negative\n",
      "\n",
      "Review: This film is about a grieving wife who lost her husband through suicide. She is tormented by her son who refused to speak after that.<br /><br />Child grief is rarely explored on film, so it is refres...\n",
      "True: negative, Pred: positive\n",
      "\n",
      "Review: ..IT'S THIS ONE! Very cool premise, right off the bat.<br /><br />Has an excellent first scene, gotta give credit where credit's due.<br /><br />Has solid characters and a decent enough script for a g...\n",
      "True: negative, Pred: positive\n",
      "\n",
      "Ensemble Accuracy: 0.9060\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import contractions\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "# --- Preprocessing utilities ---\n",
    "stopwords_english = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "negation_terms = {\"not\", \"no\", \"never\", \"n't\"}\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def handle_negation(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    output = []\n",
    "    negate = False\n",
    "    for t in tokens:\n",
    "        if t in negation_terms:\n",
    "            negate = True\n",
    "            output.append(t)\n",
    "        elif negate:\n",
    "            output.append(f\"{t}_NEG\")\n",
    "            negate = False\n",
    "        else:\n",
    "            output.append(t)\n",
    "    return ' '.join(output)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = expand_contractions(text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = handle_negation(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered = [lemmatizer.lemmatize(tok) for tok in tokens if tok not in stopwords_english]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# --- Feature transformers ---\n",
    "class TextLength(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        lengths = X.apply(lambda text: len(text.split()))\n",
    "        return lengths.to_frame(name='length')\n",
    "\n",
    "class LexiconScore(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lexicon):\n",
    "        self.lexicon = lexicon\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        scores = X.apply(lambda text: sum(self.lexicon.get(w, 0) for w in text.split()))\n",
    "        return scores.to_frame(name='lex_score')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('IMDB-Dataset.csv')\n",
    "df['cleaned'] = df['review'].apply(preprocess_text)\n",
    "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "X = df['cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Split\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, stratify=y, random_state=random_state)\n",
    "\n",
    "# Example lexicon (AFINN-like stub)\n",
    "example_lex = {'good': 2, 'great': 3, 'bad': -2, 'terrible': -3}\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.8, max_features=10000, sublinear_tf=True)),\n",
    "        ('length', Pipeline([\n",
    "            ('extract', FunctionTransformer(lambda x: x, validate=False)),\n",
    "            ('len_feat', TextLength())\n",
    "        ])),\n",
    "        ('lex', Pipeline([\n",
    "            ('extract', FunctionTransformer(lambda x: x, validate=False)),\n",
    "            ('lex_feat', LexiconScore(example_lex))\n",
    "        ])),\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Grid search params\n",
    "grid_params = {\n",
    "    'features__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'features__tfidf__min_df': [3,5],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "grid = GridSearchCV(pipeline, grid_params, cv=cv, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "# Evaluate\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\\n\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Error Analysis\n",
    "mis = df.loc[X_test.index][y_test != y_pred]\n",
    "print(\"\\nSome misclassified examples:\\n\")\n",
    "for idx, row in mis.sample(5, random_state=random_state).iterrows():\n",
    "    print(f\"Review: {row['review'][:200]}...\")\n",
    "    pred_label = best_model.predict(pd.Series([row['cleaned']]))[0]\n",
    "    pred_sentiment = 'positive' if pred_label == 1 else 'negative'\n",
    "    print(f\"True: {row['sentiment']}, Pred: {pred_sentiment}\\n\")\n",
    "\n",
    "\n",
    "# Optional: ensemble classifier\n",
    "ensemble = VotingClassifier([\n",
    "    ('lr', grid.best_estimator_),\n",
    "    ('nb', Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.8, sublinear_tf=True)),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])),\n",
    "    ('svm', Pipeline([\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1,2), max_features=5000)),\n",
    "    ('clf', CalibratedClassifierCV(LinearSVC(), cv=3))\n",
    "])),\n",
    "], voting='soft', weights=[2,1,1], n_jobs=-1)\n",
    "ensemble.fit(X_train, y_train)\n",
    "pos = ensemble.predict(X_test)\n",
    "print(f\"Ensemble Accuracy: {accuracy_score(y_test, pos):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
